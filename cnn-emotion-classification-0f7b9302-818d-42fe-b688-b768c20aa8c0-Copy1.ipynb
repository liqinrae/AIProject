{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/kaggle/input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7688e8c6b462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mKAGGLE_INPUT_SYMLINK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKAGGLE_INPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m777\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKAGGLE_INPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_is_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKAGGLE_INPUT_SYMLINK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/kaggle/input'"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATASETS\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE CELL.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "\n",
    "CHUNK_SIZE = 40960 \n",
    "DATASET_MAPPING = 'ckplus:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F65125%2F128470%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20210321%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20210321T233051Z%26X-Goog-Expires%3D259199%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3fe73639e5c3f7848c417a8d49ab363474682e26fc9f04c212bb0cc8ca070fa20799b462a139a7e8a5626148ce5e2dbc01980a3cadec1972c302e3f06eeda2461726bdd7301c12154e622442923a1358c95d644e31cc1c3a92a047e170c5d0ef0806842e37d951601059f8a3e663f045440b8b3abaaad5e0634a0471110b84cb2c59416d8a6101e3d2b5cb56f7ff0972d96c213fc73e46fe3d8aa2f62bc502c15cd0f37f55418799aaf0ff0a5e884b83685670d0b16745d22d6de0f78f1cfc1e6edb1c4486695a5bfa9caa913e28f4bbfb5424c068d0bcc4c7963e45e8c7354b25fce9c20c242d2e46f796d96a84e42c6d357cbccb4709fdc185f434c5937dd4'\n",
    "KAGGLE_INPUT_PATH='/home/kaggle/input'\n",
    "KAGGLE_INPUT_SYMLINK='/kaggle'\n",
    "\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 777)\n",
    "os.symlink(KAGGLE_INPUT_PATH, os.path.join('..', 'input'), target_is_directory=True)\n",
    "os.makedirs(KAGGLE_INPUT_SYMLINK)\n",
    "os.symlink(KAGGLE_INPUT_PATH, os.path.join(KAGGLE_INPUT_SYMLINK, 'input'), target_is_directory=True)\n",
    "\n",
    "for dataset_mapping in DATASET_MAPPING.split(','):\n",
    "    directory, download_url_encoded = dataset_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as zipfileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = zipfileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes zipped')\n",
    "            dl = 0\n",
    "            data = zipfileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = zipfileres.read(CHUNK_SIZE)\n",
    "            print(f'\\nUnzipping {directory}')\n",
    "            with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "print('Dataset import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-disgust\n",
      "\n",
      "Loaded the images of dataset-sadness\n",
      "\n",
      "Loaded the images of dataset-happy\n",
      "\n",
      "Loaded the images of dataset-anger\n",
      "\n",
      "Loaded the images of dataset-fear\n",
      "\n",
      "Loaded the images of dataset-surprise\n",
      "\n",
      "Loaded the images of dataset-contempt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(981, 48, 48, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../input/ckplus/CK+48'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=256\n",
    "img_cols=256\n",
    "num_channel=1\n",
    "\n",
    "num_epoch=10\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(48,48))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        \n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:134]=0 #135\n",
    "labels[135:188]=1 #54\n",
    "labels[189:365]=2 #177\n",
    "labels[366:440]=3 #75\n",
    "labels[441:647]=4 #207\n",
    "labels[648:731]=5 #84\n",
    "labels[732:980]=6 #249\n",
    "\n",
    "names = ['anger','contempt','disgust','fear','happy','sadness','surprise']\n",
    "\n",
    "def getLabel(id):\n",
    "    return ['anger','contempt','disgust','fear','happy','sadness','surprise'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "x_test=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transfer Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "#Load the VGG model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 16,296,775\n",
      "Trainable params: 16,296,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 7007      \n",
      "=================================================================\n",
      "Total params: 37,701,255\n",
      "Trainable params: 37,701,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import plot_model\n",
    "def define_model_original(base_model):\n",
    "    inputs1 = Input(shape=(None, None, 3,))\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    " \n",
    "    # Add the vgg convolutional base model\n",
    "    model.add(base_model)\n",
    " \n",
    "    # Add new layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1024,activation=\"relu\"))\n",
    "    model.add(Dense(units=1024,activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation=\"softmax\"))\n",
    "    \n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='mode_original.png', show_shapes=True)\n",
    "    return model \n",
    "\n",
    "def define_model_modified(base_model):\n",
    "    inputs1 = Input(shape=(None, None, 3,))\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    " \n",
    "    # Add the vgg convolutional base model\n",
    "    model.add(base_model)\n",
    " \n",
    "    # Add new layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1000,activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation=\"softmax\"))\n",
    "    \n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='mode_modified.png', show_shapes=True)\n",
    "    return model \n",
    "\n",
    "model_original = define_model_original(base_model)\n",
    "model_modified = define_model_modified(base_model)\n",
    "model_original.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "model_modified.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conduct k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 51s 2s/step - loss: 3.3391 - acc: 0.2432 - val_loss: 1.8508 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.64287, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 49s 2s/step - loss: 1.8521 - acc: 0.2692 - val_loss: 1.8812 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00002: loss improved from 2.64287 to 1.88650, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 1.8635 - acc: 0.2124 - val_loss: 1.8769 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00003: loss improved from 1.88650 to 1.84964, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 1.8069 - acc: 0.2877 - val_loss: 1.8708 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00004: loss improved from 1.84964 to 1.83320, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 1.8576 - acc: 0.2579 - val_loss: 1.9258 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00005: loss did not improve from 1.83320\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 51s 2s/step - loss: 1.8636 - acc: 0.2545 - val_loss: 1.8798 - val_acc: 0.2335\n",
      "\n",
      "Epoch 00006: loss did not improve from 1.83320\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.8355 - acc: 0.2444 - val_loss: 1.8639 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00007: loss did not improve from 1.83320\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.8874 - acc: 0.2176 - val_loss: 1.8773 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00008: loss did not improve from 1.83320\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.8417 - acc: 0.2680 - val_loss: 1.8952 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00009: loss improved from 1.83320 to 1.83316, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.8392 - acc: 0.2564 - val_loss: 1.8788 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00010: loss did not improve from 1.83316\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.8270 - acc: 0.2414 - val_loss: 1.8809 - val_acc: 0.2081\n",
      "\n",
      "Epoch 00011: loss improved from 1.83316 to 1.82684, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.7733 - acc: 0.3056 - val_loss: 1.7411 - val_acc: 0.3909\n",
      "\n",
      "Epoch 00012: loss improved from 1.82684 to 1.76590, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.7535 - acc: 0.3053 - val_loss: 1.6979 - val_acc: 0.3198\n",
      "\n",
      "Epoch 00013: loss improved from 1.76590 to 1.71033, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.6301 - acc: 0.3662 - val_loss: 1.6307 - val_acc: 0.3452\n",
      "\n",
      "Epoch 00014: loss improved from 1.71033 to 1.60597, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.5235 - acc: 0.3941 - val_loss: 1.5415 - val_acc: 0.3350\n",
      "\n",
      "Epoch 00015: loss improved from 1.60597 to 1.54112, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.4658 - acc: 0.4035 - val_loss: 1.5774 - val_acc: 0.2995\n",
      "\n",
      "Epoch 00016: loss improved from 1.54112 to 1.49396, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.5035 - acc: 0.3679 - val_loss: 1.5934 - val_acc: 0.3096\n",
      "\n",
      "Epoch 00017: loss improved from 1.49396 to 1.48050, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.4076 - acc: 0.4239 - val_loss: 1.5160 - val_acc: 0.3909\n",
      "\n",
      "Epoch 00018: loss improved from 1.48050 to 1.44384, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.3737 - acc: 0.4390 - val_loss: 1.5187 - val_acc: 0.2944\n",
      "\n",
      "Epoch 00019: loss improved from 1.44384 to 1.43810, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.4010 - acc: 0.4190 - val_loss: 1.4820 - val_acc: 0.4112\n",
      "\n",
      "Epoch 00020: loss improved from 1.43810 to 1.42829, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.3629 - acc: 0.3876 - val_loss: 1.4835 - val_acc: 0.4010\n",
      "\n",
      "Epoch 00021: loss improved from 1.42829 to 1.39576, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.3665 - acc: 0.4481 - val_loss: 1.4285 - val_acc: 0.3299\n",
      "\n",
      "Epoch 00022: loss improved from 1.39576 to 1.37917, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.3458 - acc: 0.4414 - val_loss: 1.3741 - val_acc: 0.4365\n",
      "\n",
      "Epoch 00023: loss improved from 1.37917 to 1.36247, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.3678 - acc: 0.4420 - val_loss: 1.4246 - val_acc: 0.3807\n",
      "\n",
      "Epoch 00024: loss did not improve from 1.36247\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.3452 - acc: 0.4458 - val_loss: 1.4517 - val_acc: 0.3249\n",
      "\n",
      "Epoch 00025: loss improved from 1.36247 to 1.34289, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.2787 - acc: 0.4709 - val_loss: 1.4027 - val_acc: 0.3706\n",
      "\n",
      "Epoch 00026: loss improved from 1.34289 to 1.29845, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.3160 - acc: 0.4713 - val_loss: 1.3699 - val_acc: 0.4112\n",
      "\n",
      "Epoch 00027: loss improved from 1.29845 to 1.29806, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.3447 - acc: 0.4985 - val_loss: 1.2850 - val_acc: 0.4873\n",
      "\n",
      "Epoch 00028: loss did not improve from 1.29806\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.2499 - acc: 0.5156 - val_loss: 1.2742 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00029: loss improved from 1.29806 to 1.22413, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.1917 - acc: 0.5577 - val_loss: 1.3164 - val_acc: 0.4772\n",
      "\n",
      "Epoch 00030: loss improved from 1.22413 to 1.20390, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 1.1785 - acc: 0.5361 - val_loss: 1.1401 - val_acc: 0.4924\n",
      "\n",
      "Epoch 00031: loss improved from 1.20390 to 1.16002, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 55s 2s/step - loss: 1.0883 - acc: 0.5775 - val_loss: 1.2012 - val_acc: 0.4772\n",
      "\n",
      "Epoch 00032: loss improved from 1.16002 to 1.15840, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 1.1504 - acc: 0.5445 - val_loss: 1.2136 - val_acc: 0.4772\n",
      "\n",
      "Epoch 00033: loss improved from 1.15840 to 1.14610, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 1.1176 - acc: 0.5605 - val_loss: 1.1418 - val_acc: 0.5025\n",
      "\n",
      "Epoch 00034: loss improved from 1.14610 to 1.14050, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0760 - acc: 0.5290 - val_loss: 1.2557 - val_acc: 0.4873\n",
      "\n",
      "Epoch 00035: loss improved from 1.14050 to 1.09407, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.1235 - acc: 0.5687 - val_loss: 1.1873 - val_acc: 0.4518\n",
      "\n",
      "Epoch 00036: loss did not improve from 1.09407\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0834 - acc: 0.5751 - val_loss: 1.1486 - val_acc: 0.5076\n",
      "\n",
      "Epoch 00037: loss improved from 1.09407 to 1.06141, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.0618 - acc: 0.5772 - val_loss: 1.1523 - val_acc: 0.4619\n",
      "\n",
      "Epoch 00038: loss improved from 1.06141 to 1.06074, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0525 - acc: 0.5567 - val_loss: 1.1923 - val_acc: 0.4518\n",
      "\n",
      "Epoch 00039: loss did not improve from 1.06074\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0588 - acc: 0.5705 - val_loss: 1.1215 - val_acc: 0.4772\n",
      "\n",
      "Epoch 00040: loss improved from 1.06074 to 1.02153, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0906 - acc: 0.5629 - val_loss: 1.4752 - val_acc: 0.4924\n",
      "\n",
      "Epoch 00041: loss did not improve from 1.02153\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.1342 - acc: 0.5472 - val_loss: 1.1701 - val_acc: 0.5228\n",
      "\n",
      "Epoch 00042: loss did not improve from 1.02153\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0245 - acc: 0.5575 - val_loss: 1.2112 - val_acc: 0.4822\n",
      "\n",
      "Epoch 00043: loss improved from 1.02153 to 1.01290, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0107 - acc: 0.5679 - val_loss: 1.1430 - val_acc: 0.4721\n",
      "\n",
      "Epoch 00044: loss did not improve from 1.01290\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 1.0448 - acc: 0.5883 - val_loss: 1.2436 - val_acc: 0.4924\n",
      "\n",
      "Epoch 00045: loss did not improve from 1.01290\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 1.0140 - acc: 0.5955 - val_loss: 1.1073 - val_acc: 0.5025\n",
      "\n",
      "Epoch 00046: loss did not improve from 1.01290\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 1.0728 - acc: 0.5521 - val_loss: 1.1585 - val_acc: 0.4924\n",
      "\n",
      "Epoch 00047: loss did not improve from 1.01290\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 1.0090 - acc: 0.6054 - val_loss: 1.2187 - val_acc: 0.5076\n",
      "\n",
      "Epoch 00048: loss did not improve from 1.01290\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 1.0182 - acc: 0.5827 - val_loss: 1.1307 - val_acc: 0.5178\n",
      "\n",
      "Epoch 00049: loss did not improve from 1.01290\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.9484 - acc: 0.6273 - val_loss: 1.1002 - val_acc: 0.5584\n",
      "\n",
      "Epoch 00050: loss improved from 1.01290 to 0.98803, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.9696 - acc: 0.6318 - val_loss: 1.1509 - val_acc: 0.5330\n",
      "\n",
      "Epoch 00051: loss improved from 0.98803 to 0.93468, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.9302 - acc: 0.6186 - val_loss: 1.0937 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.93468\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.9644 - acc: 0.6206 - val_loss: 1.3099 - val_acc: 0.5025\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.93468\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.9120 - acc: 0.6477 - val_loss: 1.0534 - val_acc: 0.5685\n",
      "\n",
      "Epoch 00054: loss improved from 0.93468 to 0.91537, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 54s 2s/step - loss: 0.8497 - acc: 0.6766 - val_loss: 1.1462 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00055: loss improved from 0.91537 to 0.87149, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.9122 - acc: 0.6387 - val_loss: 1.0684 - val_acc: 0.5584\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.87149\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.8827 - acc: 0.6413 - val_loss: 1.1700 - val_acc: 0.5635\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.87149\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.9329 - acc: 0.6391 - val_loss: 1.1187 - val_acc: 0.5939\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.87149\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.9294 - acc: 0.6529 - val_loss: 1.1067 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.87149\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.8925 - acc: 0.6868 - val_loss: 1.0181 - val_acc: 0.5584\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.87149\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.9027 - acc: 0.6440 - val_loss: 1.1485 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00061: loss improved from 0.87149 to 0.86881, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.9207 - acc: 0.6375 - val_loss: 1.0841 - val_acc: 0.5381\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.86881\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.9097 - acc: 0.6514 - val_loss: 0.9825 - val_acc: 0.5635\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.86881\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.9108 - acc: 0.6424 - val_loss: 1.0700 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.86881\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.8977 - acc: 0.6617 - val_loss: 1.0156 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.86881\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.8779 - acc: 0.6752 - val_loss: 1.0358 - val_acc: 0.5635\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.86881\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.8507 - acc: 0.6795 - val_loss: 1.1859 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00067: loss improved from 0.86881 to 0.86396, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.9115 - acc: 0.6405 - val_loss: 1.0106 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.86396\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.9127 - acc: 0.6292 - val_loss: 0.9358 - val_acc: 0.5888\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.86396\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.8745 - acc: 0.6721 - val_loss: 1.0437 - val_acc: 0.5635\n",
      "\n",
      "Epoch 00070: loss improved from 0.86396 to 0.86246, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.9008 - acc: 0.6574 - val_loss: 1.0139 - val_acc: 0.5635\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.86246\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.8123 - acc: 0.7028 - val_loss: 0.9969 - val_acc: 0.5685\n",
      "\n",
      "Epoch 00072: loss improved from 0.86246 to 0.84523, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.8014 - acc: 0.6573 - val_loss: 0.9233 - val_acc: 0.6294\n",
      "\n",
      "Epoch 00073: loss improved from 0.84523 to 0.82138, saving model to /kaggle/working/weights_original_0.hdf5\n",
      "Epoch 74/200\n",
      " 1/25 [>.............................] - ETA: 45s - loss: 0.7326 - acc: 0.6875"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Any results you write to the current directory are saved as output\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")\n",
    "BS = 8\n",
    "EPOCHS = 200\n",
    "result = []\n",
    "scores_loss = []\n",
    "scores_acc = []\n",
    "k_no = 0\n",
    "\n",
    "def fit_model(model, file_path, X_Train_, Y_Train, X_Test_, Y_Test):\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=8)\n",
    "    callbacks_list = [checkpoint, early]\n",
    "    hist = model.fit_generator(aug.flow(X_Train_, Y_Train), epochs=EPOCHS,validation_data=(X_Test_, Y_Test), callbacks=callbacks_list, verbose=1)\n",
    "    model.load_weights(file_path)\n",
    "    result.append(model.predict(X_Test_))\n",
    "    score = model.evaluate(X_Test_,Y_Test, verbose=0)\n",
    "    scores_loss.append(score[0])\n",
    "    scores_acc.append(score[1])\n",
    "    \n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_Train_ = x[train_index]\n",
    "    Y_Train = y[train_index]\n",
    "    X_Test_ = x[test_index]\n",
    "    Y_Test = y[test_index]\n",
    "\n",
    "    file_path_original = \"/kaggle/working/weights_original_\"+str(k_no)+\".hdf5\"\n",
    "    file_path_modified = \"/kaggle/working/weights_modified_\"+str(k_no)+\".hdf5\"\n",
    "    fit_model(model_original, file_path_original, X_Train_, Y_Train, X_Test_, Y_Test)\n",
    "    fit_model(model_modified, file_path_modified, X_Train_, Y_Train, X_Test_, Y_Test)\n",
    "    k_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
